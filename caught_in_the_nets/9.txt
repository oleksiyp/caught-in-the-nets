                                                        #9 of 29-Oct '15


 ___        _    ___           _ _        _ _          
| _ \___ __| |_ / __|__ _ _ __(_) |_ __ _| (_)____ __  
|  _/ _ (_-<  _| (__/ _` | '_ \ |  _/ _` | | (_-< '  \ 
|_| \___/__/\__|\___\__,_| .__/_|\__\__,_|_|_/__/_|_|_|
                         |_|                           
  The Economy Of The Future?

At the heart of this change is information
technology: a revolution that has the potential
to reshape utterly our familiar notions of work,
production and value; and to destroy an economy
based on markets and private ownership. Almost
unnoticed, in the niches and hollows of the
market system, whole swathes of economic life
are changing. Goods and services that no longer
respond to the dictates of neoliberalism are
appearing, from parallel currencies and time
banks, to cooperatives and self-managed online
spaces. Vast numbers of people are changing their
behaviour, discovering new forms of ownership,
lending and doing business that are distinct
from, and contrary to, the current system of
state-backed corporate capitalism.

http://www.socialeurope.eu/2015/10/postcapitalism-the-economy-of-the-future/
https://www.youtube.com/watch?v=rrzXIV8eZPo


 _                                   _   
| |_ ___ __ _ _ __   __ __ _____ _ _| |__
|  _/ -_) _` | '  \  \ V  V / _ \ '_| / /
 \__\___\__,_|_|_|_|  \_/\_/\___/_| |_\_\
                                         
  Don’t Destroy Your Dev Team By Growing

That just someone IMHO I would say

Take the time to grow sustainably

Hiring at a pace faster than 1 new member per
team every month puts a huge strain on the rest
of the team. Not only does it drain your team’s
time, but it can also increase the amount of time
it takes for new members to become productive.

Ensure team cohesion

Be as open to letting people go who detract
from team cohesion as quickly as you would for
technical reasons. It’s that important. This
doesn’t mean fire people who don’t want to
go to lunch with you, but if the team needs to
walk on egg shells around a member, that member
is probably not worth having around.

Spend time ensuring new member success

Take an interest in their opinions and ask how
they did things at their previous job. In short,
make them feel like part of the tribe.

Maintain a good ratio of senior to junior

I believe the ideal ratio for senior to junior
engineers is three senior to one junior engineer/

Be open to improvements

Just because you want a new member to become
“part of the tribe”, doesn’t mean you
can’t learn new things from them Maybe they
have advice on how to structure a sub-project
more efficiently because they ran into that at
their last gig. Maybe they have experience with
an idea you’re just now starting to experiment
with and can help you short cut most of the
pain. Maybe it’s some other suggestion that
you hadn’t thought of. You didn’t hire this
person because they were a clone of you; take
advantage of the infusion of this new “work
energy". In the same way that adding carbon to
iron makes it stronger, becoming a melting pot
of talent will make your team stronger.


https://medium.com/swlh/don-t-destroy-your-dev-team-by-growing-eef50d83090e


              _      _               _             _                       
 ___ ___ _ _ (_)__  | |_ _ _ __ _ __| |_ ___ _ _  | |__  ___ __ _ _ __  ___
(_-</ _ \ ' \| / _| |  _| '_/ _` / _|  _/ _ \ '_| | '_ \/ -_) _` | '  \(_-<
/__/\___/_||_|_\__|  \__|_| \__,_\__|\__\___/_|   |_.__/\___\__,_|_|_|_/__/
                                                                           
  Now A Reality

People might still be annoyed that we don’t
have warp drive yet, but another invention
straight out of science-fiction has now become
a reality. Researchers from the Universities
of Bristol and Sussex, England in collaboration
with Ultrahaptics have developed the first sonic
tractor beam that can lift and move objects
using nothing but sound waves.

The team used a system made of 64 miniature
loudspeakers able to create high-pitched
and high-intensity sound waves, generating
an acoustic hologram that can lift, move,
rotate and hold small objects. The system can
create three different shapes of acoustic force
fields. The first was made to resemble tweezers,
the second was a vortex-like structure which
trapped the object in the middle, and the last
one surrounds the object from all directions
and keeps it in place.

This new technology presents the opportunity
for far-reaching applications: from mechanical
support moving and assembling delicate objects,
to medical aid where miniaturized beams could
guide drugs through living tissue.

http://www.iflscience.com/sonic-tractor-beams-are-now-reality


 ___           _          _          ___            _   
|   \ ___ _  _| |_ ___ __| |_  ___  | _ ) __ _ _ _ | |__
| |) / -_) || |  _(_-</ _| ' \/ -_) | _ \/ _` | ' \| / /
|___/\___|\_,_|\__/__/\__|_||_\___| |___/\__,_|_||_|_\_\
                                                        
  doing something drastic. Do you have the right personality for programming?

Deutsche Bank has adopted the same aspirations
as Barclays. So it would seem from the German
bank’s announcement, ahead of its strategy
meeting today, that it plans to cut costs to 70%
of revenues by 2018 and to 65% by 2020 – the
latter being exactly similar to Barclays’ cost
aspirations under Antony Jenkins and Bob Diamond
before him.

Unfortunately, and as Daniel Schaefer, finance
editor of Handelsblatt, points out, that 65%
cost target looks like a big ask. In the second
quarter of 2015, the cost ratio at Deutsche Bank
was 85%. As the chart below, from Bloomberg,
shows, costs at Deutsche are higher than at
any rival firm. No wonder John Cryan says
many bonuses at the bank will be zero this
year. Bloomberg also reports that Deutsche is
cutting 26,000 jobs. However, ‘only’ 9,000
jobs are being cut on a net basis and the others
are to disappear as part of asset disposals.

Separately, now that it’s cool to get out
of banking and do a coding course, it might be
worth checking you have the right personality
for coding first. ‘Research’ reportedly shows
that the best coders are intelligent,introverted,
conscientious, and open to new things. They are
not agreeable. And they are not neurotic.

http://news.efinancialcareers.com/uk-en/224654/morning-coffee-deutsche-bank-is-doing-something-drastic-do-you-have-the-right-personality-for-programming/


                          _              _    _ _ _ _        
 _ _ ___ _ __ _ _ ___  __| |_  _ __ __ _| |__(_) (_) |_ _  _ 
| '_/ -_) '_ \ '_/ _ \/ _` | || / _/ _` | '_ \ | | |  _| || |
|_| \___| .__/_| \___/\__,_|\_,_\__\__,_|_.__/_|_|_|\__|\_, |
        |_|                                             |__/ 
  
An economics paper could be perfectly
reproducible, and yet still be utterly
flawed. This is because economists have great
freedom to pick and choose their statistical
methods and what variables to control for, which
they can “hack” until they get an exciting
or politically useful result.

This issue blew up in 2013, when Harvard
economists Carmen Reinhart and Kenneth Rogoff
were accused of statistical cherry-picking. A
paper of theirs had concluded that countries with
a debt-to-GDP ratio of more than 90 per cent
tended to have contracting economies, and was
cited by some as a justification for austerity.

Reinhart and Rogoff admitted an “accidental
omission” that led to some countries being
excluded from their analysis. But they denied
deliberately skewing the data to get the desired
result, and argued that their statistical
methods were sound (they had been accused of
“unconventional weighting” of statistics).

Another spat erupted the following year. Chris
Giles, economics editor at the Financial Times,
accused the economist Thomas Piketty, author
of the vast Capital in the 21st Century, of
using dodgy data to conclude that the UK had
become more unequal since the 1980s, something
Piketty denied.

Who is right in these two cases is moot. The
problem for economics is that there is ample
scope for certain statistical treatments to
be applied to get the desired result. Only the
authors will ever know if they have been truly
objective in their methods, says Necker (and,
given that bias can be unconscious, even they
may be in the dark).

Another problem, points out Necker, is that
perhaps more than other discipline economics
deals in correlation, not causation. Reinhart and
Rogoff’s findings, as they themselves pointed
out, only found a correlation between debt and
low growth, and thought the causation flowed both
ways (although they still argue that “growth
is an elusive goal at times of high debt”).

In the week after the Nobel Prize for economics
was awarded, all this leaves the discipline open
to the familiar charge that it is not remotely
scientific.

https://www.timeshighereducation.com/blog/news-blog-economics-based-shaky-statistics


      _       __     _ _ 
 __ _(_)_ __ / _|___| (_)
/ _` | | '_ \  _/ -_) | |
\__, |_| .__/_| \___|_|_|
|___/  |_|               
  
Gipfeli is a high-speed compression algorithm
that uses backward references with a 16-bit
sliding window, based on 1977 paper by Lempel
and Ziv, enriched with an ad-hoc entropy coding
for both literals and backward references. We
have implemented it in C++ and fine-tuned for
very high performance. The compression ratio is
similar to Zlib in the fastest mode, but Gipfeli
is more than three times faster. This positions
it as an ideal solution for many bandwidth-bound
systems, intermediate data storage and parallel
computations.

The benchmarks in this paper show that Gipfeli
can achieve compression ratios that are 30%
better than Snappy with slow-down being only
around 30%. Gipfeli achieves even higher speed
for html content and remote procedure calls
(protocol buffer in Table 7) than for text
content. We argue, using the I/O data from
the introduction, that once the compression
algorithm is fast enough, i.e. computations
are bound by external I/O costs, we need to
compress as densely as possible. At that point,
improvements in the compression ratio are more
important than running time.

The encouraging outcome of the benchmarks led
us to test Gipfeli in a real-world setting
to support our theoretical assumptions with
practical experiment. Our case study was
MapReduce technology [12] used inside Google
to run distributed computations.  A typical
computation processes terabytes of data and runs
on thousands of machines. In short, MapReduce
consists of two phases: the first phase, Map,
applies some computation in parallel to all the
input items to produce the intermediate items,
which are then merged in the second phase,
Reduce.

http://static.googleusercontent.com/media/research.google.com/ru//pubs/archive/42050.pdf
https://github.com/google/gipfeli


                 _   _           _                   _ 
 _ _ ___ __ _ __| |_(_)_ _____  | |_ _ _ ___ _ _  __| |
| '_/ -_) _` / _|  _| \ V / -_) |  _| '_/ -_) ' \/ _` |
|_| \___\__,_\__|\__|_|\_/\___|  \__|_| \___|_||_\__,_|
                                                       
  and complementary

Responsive: responds in a timely manner if at
all possible Resilient: responsive in the face of
failure Elastic: stays responsive under varying
workload Message-Driven: rely on asynchronous
message-passing

Microservices

In traditional Java apps, services are written
in a very monolithic way.

That ties back to a strong coupling between
the components in the service and between
services. App servers (WebLogic, JBoss, Tomcat,
etc.) are encouraging this monolithic model. They
assume that you are bundling your service JARs
into an EAR file as a way of grouping your
services, which you then deploy—alongside
all your other applications and services—into
the single running instance of the app server,
which manages the service “isolation” through
class loader tricks; a very fragile model.

Today we have a much more evolved foundation
for isolation—from the ground up—starting
with, for example, Docker containers, isolated
all the way up through better hardware and
communication protocols. I’m excited about
the Microservices momentum because it makes
isolation first class, which is a necessity for
resilience. You can’t build a Reactive system
without isolating failures and having a separate
context outside the failed component to react
to the failure. You need isolation in order to
avoid cascading failures.

Fast Data—the World Is Going Streaming

The whole movement towards Fast Data and
real-time data requires closed feedback loops
for getting data into and out of the system. The
benefit of Fast Data is that you get systems that
are more responsive and adaptive, allowing you
to feed the results of real-time data processing
back into the running system, which allows it
to react to change. This capability can also be
used to make these systems more resilient and
scalable, but with reduced complexity.

Event Logging as the Service of Record

Another area in which I’m seeing a lot of
Reactive innovation, specifically on the JVM,
is when event logging is being used as the
“Service of Record.” In event logging,
each state change to the application is
materialized as an event in the log. What you
get is a database with the full history of the
application; a database of facts, rather than
the traditional SQL database approach that only
works with a "cache of the subset of the log,"
as Pat Helland aptly put it. If your durable
state is based on an event log, it can be easily
replicated and replayed somewhere else to bring
the system or component up to speed wherever it
is. This is a great pattern for failure handling
in distributed stream processing—if one thing
fails it can be brought back up to speed and
continue.

Today we’re seeing the same shift for
Reactive. The core message of Reactive is
aimed at core principles rather than tools
and techniques. But Microservices, Fast Data,
and Event Logging are great examples of how
implementation patterns within the Reactive
movement are starting to get more definition
and momentum.

https://dzone.com/articles/reactive-trends-on-the-jvm
http://www.reactivemanifesto.org/


      _                   _                    _ _   _           
 _ __| |_  __ _ ___ ___  | |_ _ _ __ _ _ _  __(_) |_(_)___ _ _   
| '_ \ ' \/ _` (_-</ -_) |  _| '_/ _` | ' \(_-< |  _| / _ \ ' \  
| .__/_||_\__,_/__/\___|  \__|_| \__,_|_||_/__/_|\__|_\___/_||_| 
|_|                                                              
  observed that was thought impossible

In 1937 physicist Lev Landau established
a theoretical framework that explained and
classified all of the known phases, but in the
late 1980s it was realized that there existed
a second group of phases that occur at very
low temperatures that do not fit in Landau's
theory. The new phases were named topological
phases, while the traditional phases described
by Landau's theory are called broken symmetry
phases, said Eduardo Fradkin, a professor
of physics at the University of Illinois at
Urbana-Champaign and director of the Institute
for Condensed Matter Theory at the University
of Illinois who participated in the research
and is a co-author of the paper.

Topological phases have been an area of focus in
the field of condensed matter physics because
of their special properties and potential
technological applications, including quantum
computing.

Csáthy specializes in the study of topological
phases in semiconductors and works to discover
and characterize rare topological phases. His
team employs novel investigative techniques
for the study of electrons freely flowing
in ultrapure gallium-arsenide semiconductor
crystals, which is a perfectly aligned lattice
of gallium and arsenic atoms that can capture
electrons on a two-dimensional plane.

The extremely low temperature encourages the
electrons to enter into exotic states where
they no longer obey the laws of single particle
physics, but instead are governed by their
mutual interactions. A collective motion of the
electrons is then possible that is described by
the laws of quantum mechanics, instead of the
laws of classical mechanics, he said.  Csáthy's
research team was focusing on the fractional
quantum Hall state at quantum number 5/2, which
is believed to be a non-Abelian topological
phase. Non-Abelian states are different from
anything known in nature, he said.

"Imagine eggs in an egg carton as electrons
arranged in a certain formation," he said. "The
eggs are identical just like the electrons are
identical particles. If you swap one egg with
another, nothing has changed. It is still a group
of eggs in the same formation. If someone did not
see the swap, he or she would never know it had
happened. In non-Abelian states, if you swap two
electrons, it causes a change to the entire group
and the egg carton enters an entirely different
state. This ability of a swap to affect the state
of the entire group is a very special property."

It is thought that if this property could be
harnessed, it could be used in quantum computing,
he said.

http://phys.org/news/2015-10-physicists-phase-transition.html#jCp


            _      _   _          _         _         _            _    
__ __ _____(_)__ _| |_| |_ ___ __| |  _ __ (_)_ _ ___| |_  __ _ __| |_  
\ V  V / -_) / _` | ' \  _/ -_) _` | | '  \| | ' \___| ' \/ _` (_-< ' \ 
 \_/\_/\___|_\__, |_||_\__\___\__,_| |_|_|_|_|_||_|  |_||_\__,_/__/_||_|
             |___/                                                      
  similarity search

If you following Minning massive datasets,
you know that matching large number of similiar
documents could be done with hashing.

This team have experience upgrading it to what
they call it "weight min-hash"

Suppose tokens have different weights and these
weights are also known beforehand, the question
now becomes how to incorporate token weights
into min-hash so that similar logs under weighted
Jaccard similarities have high probabilities to
be mapped into the same bucket. Note in min-hash,
the hashing function, which is a mapping from
a token to a random integer, is only used for
perturbing orders of tokens. That means you can
use original tokens as hashing keys. You can
also use randomly-generated strings as hashing
keys. The advantage of randomly-generated keys
is that you can assign different numbers of
random keys to the same token according to its
weight. In particular, tokens with large weights
should be assigned more random keys, while
tokens with small weights should be assigned less
random keys. That is the core trick of weighted
min-hash[3][6]. If all token weights are assumed
to be positive integers which can be realized
by scaling and discretization, then a simple
approach is to generate w(t) random keys for the
token t where w(t) is its weight. For example,
if the weight of token “fail” is 3, then we
will assign 3 random keys such as “fail0″,
“fail1″, “fail2″ to it.

Apart from the random keys method described
above, monotonic transformation[3] is another
approach for incorporating token weights into
min-hash. In[3], the authors did a lot of
experiments to compare min-hash and weighed
min-hash for image retrieval and concluded
that weighted min-hash performs much better
than min-hash. Our analytics team got the same
conclusion after running min-hash and weighted
min-hash for machine log analysis.

https://www.sumologic.com/2015/10/22/rapid-similarity-search-with-weighted-min-hash/


  __      _                       __     _   ___ 
 / _|_  _| |_ _  _ _ _ ___   ___ / _|   /_\ |_ _|
|  _| || |  _| || | '_/ -_) / _ \  _|  / _ \ | | 
|_|  \_,_|\__|\_,_|_| \___| \___/_|   /_/ \_\___|
                                                 
  separating Facts from Fictions

The news is a tough nut to crack in today’s
over-stimulated and often sensational,
media-driven world. This is true more than
ever in the coverage of artificial intelligence
(AI). Many of us are not sure if AI is going to
wake up any moment and wreak insidious havoc,
taking over or destroying society as we know it.

Dr. Andras Kornai is all about separating AI
fact from fiction.

In a recent interview, Andras also made clear
that he is adamant about convincing the public
that much of their assumptions about AI are real
and not relegated to fiction. AI is with us now,
and it is everywhere – but it’s nowhere
close to becoming aware of itself and making
intention-driven decisions.

While many are aware of the reach of AI into
our interwoven, digital lives – our computers,
phones, and other “smart” and mobile devices
– many are unaware of the algorithms that drive
much of this technology, which has led to the
boom in the past decade in deep-learning. In
fact, the biggest societal change in the past
20 years, says Andras, was with the introduction
of cell phones. “Instant communication, it’s
not overtly visible…it’s subtle,” he says.


http://ieet.org/index.php/IEET/more/faggella20151025


              _ _         _        _ 
 _ __  ___ __| (_)__ __ _| |  __ _(_)
| '  \/ -_) _` | / _/ _` | | / _` | |
|_|_|_\___\__,_|_\__\__,_|_| \__,_|_|
                                     
  Humankind’s best chance for a healthier future

Today, engineers are working on an AI system
that might uncover subtle patterns of disease
in medical images, laboratory tests and patient
histories. A San Francisco startup called Enlitic
has raised $2 million to develop algorithms,
imbued with artificial intelligence, that
leverage deep learning to find these diagnostic
nuances. This software will not render a
diagnosis. It will not replace physicians. It
will assist them.

Clinical decision support (CDS) systems may be
the ideal situation in which to nurture such
a human-machine collaboration. The practice
of CDS has hardly begun. To date, its use has
been mandated for only a handful of on-screen
pop-ups in the increasingly EMR-based environment
of healthcare. But, CDS is all but assured of
eventually becoming a critical part of medical
practice. When it does, intelligent CDS will be
a necessity to sift through Big Data for the
information to keep patients on the rails of
best practices.

As each patient presents unique challenges,
AI might consider different treatment options,
calculating the possible outcomes and presenting
them to physicians. In so doing, AI may initially
prove its value in health IT, doing for human
professionals what they do not have the time to
do themselves.

Rather than fretting over how AI might be the
ruination of humankind, we should recognize that
machine intelligence may be our best hope for
a bright future. It’s obvious we need help.

Right now a misguided and determined group of
throwbacks – fearful that vaccines cause autism
– are choosing not to immunize their children
while urging other parents to do the same. In
their wake, polio and measles, once thought to
be eradicated, are again striking.

The improper use of antibiotics in human medicine
and agriculture are producing superbugs that
threaten plagues like we have not seen in
centuries.

Clearly, human intelligence has had its chance
and come up short.

It’s time AI got a shot.

http://www.cio.com/article/2997174/big-data/artificial-intelligence-humankinds-best-chance-for-a-healthier-future.html


 _          _         _     _    _   
| |_ ___ __| |_    __| |___| |__| |_ 
|  _/ -_) _| ' \  / _` / -_) '_ \  _|
 \__\___\__|_||_| \__,_\___|_.__/\__|
                                     
  What It Is & Isn't

A typical example for incurring technical debt in
code is that huge source file every developer
fears to touch. Everyone on the team knows
that it needs to be broken into more manageable
pieces, but it would delay upcoming features by
at least two weeks. Touching this module without
refactoring it is adding to the technical debt
of your product. Every such change will make the
eventual refactoring harder and therefore needs
to be paid back later – with interest. The
interest you’ll have to pay is the added
complexity of every change you added. The
module grows with every code addition making
its refactoring (and even the decision to do so)
ever more difficult.

An example for technical debt from the
operations side of things is deploying your
application in only one availability zone in your
datacenter even though you have demanding uptime
requirements. Setting up a split environment,
which covers multiple availability zones is
more work. It might be necessary to defer this
additional work to be able to deliver critical
features to your clients. In this scenario,
technical debt does not materialize in added
complexity but in higher risk of downtime. To
avoid necessary work right now, you introduce
single points of failure which will ultimately
lower your uptime.

So, what isn’t technical debt?

Unnecessary complexity, dirty hacks, and
unreadable code are not technical debt. There
is no good reason for introducing such a mess
in the first place. If developers feel that
they don’t have the time to write simple,
maintainable code they’re clearly lacking
experience and professionalism.

https://dzone.com/articles/technical-debt-what-it-is-isnt


          _ _                              _ _      _    
 ___ _ __(_) |___ _ __ ____  _   ____ __ _(_) |_ __| |_  
/ -_) '_ \ | / -_) '_ (_-< || | (_-< V  V / |  _/ _| ' \ 
\___| .__/_|_\___| .__/__/\_, | /__/\_/\_/|_|\__\__|_||_|
    |_|          |_|      |__/                           
  researchers discover an epilepsy switch

MTF1 acts like a switch in the brain

The team of Prof. Becker, together with
scientists from the departments of Experimental
Epileptology and Neuroradiology of the University
of Bonn Hospital as well as from the Hebrew
University in Jerusalem (Israel), have now
decoded a signaling pathway which is involved in
the onset of a seizure disorder. If the number
of zinc ions increases following transient severe
brain damage, these ions dock in greater numbers
onto a switch, the so-called metal-regulatory
transcription factor 1 (MTF1). This leads to
a large increase in the amount of a special
calcium ion channel in the nerve cells and
overall, this significantly boosts the risk of
epileptic seizures.

Hope for new options for diagnosis and treatment
The scientists hope that new treatment options
will open up for epilepsy patients as a
result of their discovery. "About one-third
of patients with temporal lobe epilepsy do
not respond to medications. Our research
is therefore increasingly focusing on new
therapeutic options that have few side effects,"
states Prof. Becker. If the zinc ions or the
transcription factor MTF1 were specifically
inhibited in the brain, it is possible that
the development of a seizure disorder could
be prevented. "However, this still needs to be
demonstrated in further studies," says Dr. Karen
M.J. van Loo.

http://medicalxpress.com/news/2015-10-epilepsy.html


